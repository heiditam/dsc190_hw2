---
title: "Video Game Preferences Among UC Berkeley Stats Students in Fall 1994"
author: Heidi Tam and Paige Pagaduan
output: pdf_document
date: "2024-10-19"
font: 12pt
---

# 0. Contribution Statement

\pagebreak

\pagenumbering{arabic}

# Introduction

### Data
The data from videodata.txt and videoMultiple.txt were collected as part of a survey for students at UC Berkeley enrolled in a particular statistics course that had about 3000-4000 students. Students from Statistics 2, Section 1, in Fall 1994, were invited to participate in the survey if they partook in the second exam of the course. Within this section, 314 students were eligible to participate and 95 students were randomly selected through a random number generator.
The data from videodata.txt was the first part of the survey and asked about background information of the survey participant. The data was numerical and discrete (e.g., Time, the number of hours played in the week prior to the survey as an integer) or categorical but encoded as a numerical value (e.g., Like to play, rated on a scale of 1 to 5).
The data from videoMultiple.txt was the second part of the survey and covered whether the student likes or dislikes playing video games. In these questions, more than one response could be given. The data in this file was recorded as binary values indicating whether the student selected that option. Some columns also contain string values if the student provided a reason that was not given as to why they dislike video games. 

\pagebreak

# Basic Analysis

## Question 01

### Methods
First, we loaded the data in through R.

```{r setup, include=FALSE}

# TODO: bootstrap

knitr::opts_chunk$set(echo = TRUE)
video_data = read.table("videodata.txt", header=TRUE)
video_multiple = read.table("videoMultiple.txt", header=TRUE)
```

To determine a point estimate of the fraction of students we played a video game in the week prior to the survey, we need the total number of students. The video_data table has 91 observations and 15 variables. Since we have no way of proving that each student only filled out the form once, we will assume so for this assignment. 

Data Cleaning:

We will replace all values of 99 with NA. 

```{r}
video_data[video_data == 99] <- NA
```

POINT ESTIMATE: We can count the number of students who played a video game in the week prior to the survey by counting the number of students who played a video game for more than zero hours in the week prior. 
```{r}
n <- nrow(video_data)
played_count <- sum(video_data$time > 0) 
point_estimate_fraction <- played_count / n
```

INTERVAL ESTIMATE: We will construct a confidence interval that contains a range of values that likely contain the population parameter, the proportion of all students who answered the survey who played a video game in the week prior to the survey. 
For a 95% confidence interval, we will use z = 1.96.

```{r}
z <- 1.96
lower_interval_estimate_fraction <- point_estimate_fraction - z * sqrt(point_estimate_fraction * (1 - point_estimate_fraction) / n)
upper_interval_estimate_fraction <- point_estimate_fraction + z * sqrt(point_estimate_fraction * (1 - point_estimate_fraction) / n)
```

We constructed the confidence interval using the formula
p-hat = z +/- sqrt((p-hat)*(1 - p-hat) / n), where p-hat is the sample proportion of students who played a video game in the past week and n is the sample size. Z is the Z-score for the confidence level we chose (95%). 

### Analysis

Point estimates are a single numerical value that summarizes the data based on the sample data. In this case, point_estimate_fraction is a point estimate (sample proportion) that estimates the proportion of students who played a video game in the week through a single number, approximately 0.374.
Interval estimates, on the other hand, provide some leeway in case the point estimate is close but not exactly the same as the population proportion. The interval estimate uses the point estimate and creates a range depending on our chosen confidence level, which in this case, is 95%. In this case, we can say that if we take many independent samples of size n = 91 from the population, about 95% of them would cover the true population proportion (p). 
It is important to note that it would be incorrect to state we are 95% confident that p is between 0.274 (the lower interval) and 0.473 (the upper interval) because the confidence interval is not measuring our confidence in a particular interval. It is also incorrect to state that there is a 95% chance that p is between 0.274 and 0.473 because p is a fixed value, and we thus should not calculate the probability of it occurring within a range. 

\pagebreak

## Question 02
### Methods
To understand the differences in distributions of the hours played per week and the reported frequency of play, we graphed each as a frequency histogram. 

```{r echo=FALSE}
par(mfrow=c(1, 2))
hist(video_data$freq, main="Frequency of Video Game Play", xlab="Frequency", axes=FALSE)
axis(2)

axis(1, at=c(1, 2, 3, 4), labels=FALSE, tick=TRUE)
text(x=c(1, 2, 3, 4), y=par("usr")[3] - 0.5, 
     labels=c("Daily", "Weekly", "Monthly", "Semesterly"), 
     srt=45, adj=1, xpd=TRUE, cex=0.8)

hist(video_data$time, main="Time of Video Game Play", xlab="Time Played a Week Prior (hours)")
```

Additionally, we examined the basic summary statistics of first the frequency cateogory then time category.

```{r echo=FALSE}
library(pander)
pander(summary(video_data$freq))
pander(summary(video_data$time))
```

### Analysis
Based on the frequency histograms, most students report their video gaming frequency to be weekly, followed by semesterly, then monthly, and finally daily. A majority of survey submissions report the count of hours spent playing video games in the week prior to be between 0 and 5, with some people reporting 10 to 15 hours and fewer 25 to 30 hours.  

### Conclusion
The results of graphing each feature of the survey 

## Question 03
### Methods

```{r}
hist(video_data$time)
```

Since the distribution of the amount of time people played video games in the week prior to taking the survey is not approximately normal, we need to create a bootstrap population. We can do this by repeating every sample for 314/ 91 is about 3.45 times since our sample was drawn from a population of N = 314 eligible students. 

```{r}
set.seed(371)
shuffle.ind = sample(1:nrow(video_data))
boot.population <- rep(video_data$time[shuffle.ind], length.out = 314)
# Choose our first sample
sample1 <- sample(boot.population, size = 91, replace = FALSE)

# Choose 400 samples from our bootstrap population and store them in a 2D Array
# Each row represents a bootstrap sample of size 91 (we have 400 rows/samples)
# Each column represents an element (we have 91 elements)
set.seed(6653)
B = 400
boot.sample <- array(dim = c(B, 91))
for (i in 1:B) {
  boot.sample[i, ] <- sample(boot.population, size = 91, replace = FALSE)
}

# Calculate the sample mean of each bootstrap sample
boot.mean <- apply(X = boot.sample, MARGIN = 1, FUN = mean)

# Histogram of Bootstrap sample means
hist(boot.mean, breaks = 20, probability = TRUE, density = 20, col = 3, border = 3)
lines(density(boot.mean, adjust = 2), col = 2)

# QQ plot of Bootstrap sample means
par(pty = 's')
qqnorm(boot.mean)
qqline(boot.mean)
```

Both the histogram and QQ plot (the points closely follow the straight reference line) imply the bootstrap sample means are approximately normally distributed. This means we can construct a 95% confidence interval. 

POINT ESTIMATE: the mean of the bootstrapped sample means
```{r}
# Close to the sample average
point_estimate_average <- mean(boot.mean)
```

CONFIDENCE INTERVAL: contains a range of values that likely contain the population parameter, the average amount of time spent playing video games in the week before the survey for UC Berkeley students enrolled in a particular section.
```{r}
# Bootstrap confidence interval
# Find the values between 2.5% to 97.5% to capture the middle 95% of the data.
interval_estimate <- c(quantile(boot.mean, 0.025), quantile(boot.mean, 0.975))
lower_interval_estimate_average <- interval_estimate[[1]]
upper_interval_estimate_average <- interval_estimate[[2]]
```

### Analysis
The point estimate average, about 1.242, means that after bootstrapping from the original population, we would expect the average amount of time spent playing video games in the week prior to the survey to be about 1.242 hours. 
The confidence interval estimate average, from about 0.676 to 1.902, means that if we took many independent samples of size 91 from the population, 95% of the samples would capture the true population parameter within this range. 

### Conclusion
From the histogram and the qq plot, we can see the sample distribution of the number of hours spent playing video games is extremely skewed. Additionally, n is large but n / N = 91/314 is not small. We are unsure about whether the probability distribution of the sample average follows a normal curve, so can bootstrap to estimate the properties of the population. We collected 400 samples, each with a size of 91 since our initial sample was of size 91. We double checked for normality using a histogram and QQ Plot before continuing with bootstrapping. Then, we created the point estimate by taking the mean of the bootstrapped samples. Our point estimate was about 1.242, which would be the average amount of time we would expect to be spent playing video games in the week prior to the survey if we had to summarize this in a single value. We also created a 95% confidence interval, which captures 95% of the samples within the range of 0.676 to 1.902 hours. 

## Question 04
### Methods
The second question of the Attributes section keeps track of why people play the games checked above. This section was marked with binary values, where 1 means that the person selected that option and 0 means that the person didn't select the option. We made a list of the mean results for each option in this question, which represents the proportion of people who chose that particular option as why they enjoy playing video games.

```{r}
reasons_played <- list()
for (col in c("graphic", "relax", "coord", "challenge", "master", "bored")){
     mean_value <- mean(video_multiple[[col]], na.rm = TRUE)
     reasons_played[[col]] <- mean_value
}
```

This yields 0.26 for graphic, 0.67 for relax, 0.05 for coordination, 0.24 for challenge, 0.29 for master, and 0.28 for bored. Since two-thirds of gamers listed relaxation as one of their reasons for playing, it’s reasonable to conclude that most people who play video games likely find them enjoyable.

People who do not play video games were told to skip the first question. This means that they marked neither 0 nor 1 in the question options and left them as NA. We can calculate the number of people who skipped the first question by choosing a column and counting the NAs. We can choose a random column because the number of NAs should be the same in each category (Action, Adventure, Simulation, Sports, Strategy) if people followed directions and skipped the question when they have not played video games before. 

```{r}
sum(is.na(video_multiple$action))
```

Four people out of 91 respondents have not played video games before. Since two-thirds of the people who DO play video games play them for relaxation, that means 2/3 * (91 - 4)  = 58 people out of 91 who enjoy playing video games. That's equivalent to approximately 63.74%. This is more than half, so it is fair to say in general, most students enjoy playing video games!

By sorting the reasons_played list in decreasing order by value, we can see the two most popular reasons for playing video games are for relaxation and people enjoy the feeling of mastery.
```{r}
sort(unlist(reasons_played), decreasing = TRUE)
```

We will repeat this process to determine the main reasons why people dislike playing video games. 

```{r}
disadvantages <- list()
for (col in c("time", "frust", "lonely", "rules", "cost", "bored", "friends", "point")){
  mean_value2 <- mean(video_multiple[[col]], na.rm = TRUE)
  disadvantages[[col]] <- mean_value2
}
sort(unlist(disadvantages), decreasing = TRUE)
```

The top two reasons why people dislike playing video games are time and cost.
